{"componentChunkName":"component---src-templates-post-js","path":"/posts/scaling-with-queues/","result":{"data":{"markdownRemark":{"html":"<p>Our home-grown <a href=\"http://visualwebsiteoptimizer.com/split-testing-blog/geo-distributed-architecture/\">geo-distributed architecture</a>\nbased CDN allows us to delivery dynamic javascript content with minimum\nlatencies possible. Using the same architecture we do data acquisition as well.\nOver the years we've done a lot of changes to our backend, this post talks\nabout some scaling and reliability aspects and our recent work on making fast and\nreliable data acquisition system using message queues which is in production for\nabout three months now. I'll start by giving some background on our previous\narchitecture.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Web_bug\">Web beacons</a> are widely used to do data\nacquisition, the idea is to have a webpage send us data using an HTTP request\nand the server sends some valid object. There are many ways to do this. To keep\nthe size of the returned object small, for every HTTP request we\nreturn a tiny 1x1 pixel gif image and our geo-distributed architecture along with\nour managed Anycast DNS service helps us to do this with very low latencies,\nwe aim for less than 40ms. When an HTTP request hits one of our data acquisition servers, <a href=\"http://openresty.org\">OpenResty</a>\nhandles it and our Lua based code processes the request in the same process thread.\nOpenResty is a <code class=\"language-text\">nginx</code> mod which among many things bundles <code class=\"language-text\">luajit</code> that allows\nus to write URL handlers in Lua and the code runs within the web server. Our Lua code\ndoes some quick checks, transformations and writes the data to a <a href=\"http://redis.io\">Redis</a>\nserver which is used as fast in-memory data sink. The data stored in Redis is\nlater moved, processed and stored in our database servers.</p>\n<div style=\"text-align:center; margin:5px\">\n<img src=\"/images/2013/09/0.png\"><br>\n<p>Previous Architecture</p>\n</div>\n<p>This was the architecture when I had <a href=\"http://team.wingify.com/friday-engineering-talks-at-wingify\">joined</a>\nWingify couple of months ago. Things were going smooth but the problem was we were\nnot quite sure about data accuracy and scalability. We used Redis as a fast\nin-memory data storage sink, which our custom written PHP based queue infrastructure\nwould read from, our backend would process it and write to our database servers.\nThe PHP code was not scalable and after about a week of hacking, exploring options\nwe found few bottlenecks and decided to re-do the backend queue infrastructure.</p>\n<p>We explored many <a href=\"http://queues.io\">options</a> and decided to use <a href=\"http://www.rabbitmq.com\">RabbitMQ</a>.\nWe wrote a few proof-of-concept backend programs in Go, Python and PHP and\ndid a lot of testing, benchmarking and real-world <a href=\"http://loader.io\">load testing</a>.</p>\n<p>Ankit, Sparsh and I discussed how we should move forward and we finally\ndecided to explore two models in which we would replace the home-grown PHP queue\nsystem with RabbitMQ. In the first model, we wrote directly to RabbitMQ from the\nLua code. In the second model, we wrote a transport agent which moved data from Redis\nto RabbitMQ. And we wrote RabbitMQ consumers in both cases.</p>\n<p>There was no Lua-resty library for RabbitMQ, so I wrote one using <code class=\"language-text\">cosocket</code> APIs\nwhich could publish messages to a RabbitMQ broker over STOMP protocol. The library\n<a href=\"https://github.com/wingify/lua-resty-rabbitmqstomp\">lua-resty-rabbitmqstomp</a> was\nopensourced for the hacker <a href=\"https://groups.google.com/forum/?fromgroups#!forum/openresty-en\">community</a>.</p>\n<p>Later, I rewrote our Lua handler code using this library and ran a <a href=\"http://loader.io\">loader.io</a>\nload test. It failed this model due to very <a href=\"http://ldr.io/154Xf1h\">low throughput</a>,\nwe performed a load test on a small 1G DigitalOcean instance for both models.\nFor us, the STOMP protocol\nand slow RabbitMQ STOMP adapter were performance bottlenecks. RabbitMQ was not\nas fast as Redis, so we decided to keep it and work on the second\nmodel. For our requirements, we wrote a proof-of-concept Redis to RabbitMQ transport\nagent called <code class=\"language-text\">agentredrabbit</code> to leverage Redis as a fast in-memory storage sink and\nuse RabbitMQ as a reliable broker. The <em>POC</em> worked well in terms of performance,\nthroughput, scalability and failover. In next few weeks we were able to write a\nproduction level queue based pipeline for our data acquisition system.</p>\n<p>For about a month, we ran the new pipeline in production against the existing one,\nto A/B test our backend :) To do that we modified our Lua code to write to two\ndifferent Redis lists, the original list was consumed by the existing pipeline, the other was\nconsumed by the new RabbitMQ based pipeline. The consumer would process and write\ndata to a new database. This allowed us to compare realtime data from the two\npipelines. During this period we tweaked our implementation a lot, rewrote the\nproducers and consumers thrice and had two major phases of refactoring.</p>\n<div style=\"text-align:center; margin:5px\">\n<img src=\"/images/2013/09/1.png\"><br>\n<p>A/B testing of existing and new architecture</p>\n</div>\n<p>Based on <a href=\"http://ldr.io/1565jPu\">results</a> against a 1G DigitalOcean instance like\nfor the first model and against the A/B comparison of existing pipeline in realtime,\nwe migrated to the new pipeline based on RabbitMQ. Other issues of HA,\nredundancy and failover were addressed in this migration as well.\nThe new architecture ensures no single point of failure and has mechanisms to\nrecover from failure and fault.</p>\n<div style=\"text-align:center; margin:5px\">\n<img src=\"/images/2013/09/2.png\"><br>\n<p>Queue (RabbitMQ) based architecture in production</p>\n</div>\n<p>We've <a href=\"https://github.com/wingify/agentredrabbit\">opensourced <code class=\"language-text\">agentredrabbit</code></a>\nwhich can be used as a general purpose fast and reliable transport agent for\nmoving data in chunks from Redis lists to RabbitMQ with some assumptions and queue\nname conventions. The flow diagram below has hints on how it works, checkout the\n<a href=\"https://github.com/wingify/agentredrabbit\">README for details</a>.</p>\n<div style=\"text-align:center; margin:5px\">\n<img src=\"/images/2013/09/3.png\"><br>\n<p>Flow diagram of \"agentredrabbit\"</p>\n</div>\n<br>\n[Discussion on Hacker News](https://news.ycombinator.com/item?id=6359786)","timeToRead":4,"excerpt":"Our home-grown geo-distributed architecture\nbased CDN allows us to delivery dynamic javascript content with minimum\nlatencies possibleâ€¦","frontmatter":{"title":"Scaling with Queues","author":"Rohit Yadav","authorslug":"rohit_yadav"},"fields":{"slug":"/posts/scaling-with-queues/","date":"September 01, 2013"}}},"pageContext":{"slug":"/posts/scaling-with-queues/","date":"2013-09-01T18:30:00.000Z","nexttitle":"Internship experience @Wingify","nextslug":"/posts/internship-experience-at-wingify/","prevtitle":"Automated e2e testing- WebDriverJS, Jasmine and Protractor","prevslug":"/posts/e2e-testing-with-webdriverjs-jasmine/"}}}