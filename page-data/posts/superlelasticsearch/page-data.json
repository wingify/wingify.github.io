{"componentChunkName":"component---src-templates-post-js","path":"/posts/superlelasticsearch/","result":{"data":{"markdownRemark":{"html":"<p>We have been using <a href=\"https://www.elastic.co/products/elasticsearch\">Elasticsearch</a> for <a href=\"http://engineering.wingify.com/posts/elasticsearch-for-analytics/\">storing analytics data</a>.\nThis data stored in Elasticsearch is used in the Post Report Segmentation\nfeature in VWO. So the amount of data getting stored in Elasticsearch is tied\nup to the number of campaigns currently being run by our customers. And often\nwe need to have custom tooling to work with this data and the requirements of\nsuch tooling are also not common. This blog post is about how we solved some\nissues by building some missing blocks in the\n<a href=\"https://github.com/elastic/elasticsearch-py\">Official Elasticsearch Python</a> client while working on this project.</p>\n<p>The code base where implementation of this feature (Post Report Segmentation)\nlies is all written in Python. When we were starting out, we had to decide\nwhich client to use because there were many out there. Eliminating some was\nreally easy because they were tied to certain frameworks like <a href=\"http://www.tornadoweb.org/en/stable/guide.html\">Tornado</a>\nand <a href=\"https://twistedmatrix.com/trac/\">Twisted</a>. And we were not sure which path to take initially so we\ndecided to keep things simple, avoid early optimization and not use any of\nthese framework heavily dependent on Non-Blocking IO. If we needed any of that\nlater, Gevent could be put to use (in fact thatâ€™s exactly what we did). Even\nfor the simpler way there were quite a few options. The deciding factors for\nus were:</p>\n<ol>\n<li>Maintenance commitment from the author</li>\n<li>Un-opinionated</li>\n<li>Simple design</li>\n</ol>\n<p>Considering all these factors, we decided to go with the Official Python\nClient for Elasticsearch. And we didn't really come across any issues and\nproblems according to our simple requirements. It is fairly extensible and\ncomes with some standard batteries included with it. For everything else, you\ncan extend it - thanks to its simple design.</p>\n<p>It worked well for a while until we had to add some internal tooling where we\nneeded to work a lot with Elasticsearch's <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html\">Scroll API</a> and\n<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/1.4/docs-bulk.html\">Bulk APIs</a>.</p>\n<h2 id=\"bulk-api\" style=\"position:relative;\"><a href=\"#bulk-api\" aria-label=\"bulk api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bulk API</h2>\n<p>Elasticsearch's Bulk API lets you club together multiple individual API calls\ninto one. This is used a lot in speeding up indexing and can be very useful if\nyou are doing a lot of write operations in Elasticsearch.</p>\n<p>The way you work with Bulk APIs is that you\nconstruct a different kind of request body for bulk requests and use the client\nfor sending that request data. The HTTP API that Elasticsearch exposes for bulk\noperations is semantically different than the API for individual operations.</p>\n<p>Consider this. If you were to index a new document, update an existing document\nand delete another existing document in Elasticsearch, you can do it like so:</p>\n<p>{% highlight python %}\nfrom elasticsearch import Elasticsearch</p>\n<p>client = Elasticsearch(hosts=['localhost:9200'])\nclient.index(index='test<em>index</em>1', doc<em>type='test</em>doc<em>type',\nbody=dict(key1='val1'))\nclient.update(index='test</em>index<em>3', doc</em>type='test<em>doc</em>type',\nid=456, body={\n'script': 'ctx.<em>source.count += count',\n'params': {\n'count': 1\n}\n})\nclient.delete(index='test</em>index<em>2', doc</em>type='test<em>doc</em>type',\nid=123)\n{% endhighlight %}</p>\n<p>If you were to achieve the same thing using Bulk APIs, you would end up writing\ncode like this:</p>\n<p>{% highlight python %}\nfrom elasticsearch import Elasticsearch</p>\n<p>client = Elasticsearch(hosts=['localhost:9200'])</p>\n<p>bulk_body = ''</p>\n<h1 id=\"index-operation-body\" style=\"position:relative;\"><a href=\"#index-operation-body\" aria-label=\"index operation body permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>index operation body</h1>\n<p>bulk<em>body += '{ \"index\" : { \"</em>index\" : \"test<em>index</em>1\", \"<em>type\" : \"test</em>doc<em>type\", \"</em>id\" : \"1\" } }\\n'\nbulk_body += '{ \"key1\": \"val1\" }\\n'</p>\n<h1 id=\"update-operation-body\" style=\"position:relative;\"><a href=\"#update-operation-body\" aria-label=\"update operation body permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>update operation body</h1>\n<p>bulk<em>body += '{ \"update\" : {\"</em>id\" : \"456\", \"<em>index\" : \"test</em>index<em>3\", \"</em>type\" : \"test<em>doc</em>type\"} }\\n'\nbulk<em>body += '{ \"script\": \"ctx.</em>source.count += count\", \"params\": { \"count\": 1 } }\\n'</p>\n<h1 id=\"delete-operation-body\" style=\"position:relative;\"><a href=\"#delete-operation-body\" aria-label=\"delete operation body permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>delete operation body</h1>\n<p>bulk<em>body += '{ \"delete\" : { \"</em>index\" : \"test<em>index</em>2\", \"<em>type\" : \"test</em>doc<em>type\", \"</em>id\" : \"123\" } }'</p>\n<h1 id=\"finally-make-the-request\" style=\"position:relative;\"><a href=\"#finally-make-the-request\" aria-label=\"finally make the request permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>finally, make the request</h1>\n<p>client.bulk(body=bulk_body)\n{% endhighlight %}</p>\n<p>There is a ton of difference in how bulk operations work on the code and API\nlevel as compared to individual operations.</p>\n<ol>\n<li>The request body is considerably different in Bulk APIs as compared to their\nindividual APIs.</li>\n<li>The responsibility of properly serializing request body is now shifted to\nthe developer whereas this can be handled at the client level.</li>\n<li>Serialization format itself is a mixup of JSON and new-line character\nseparated string.</li>\n</ol>\n<p>If you are depending a lot on bulk operations, these problems will bite you when\nyou start using it at a lot of places in your code. The flexibility of\nmanipulating bulk request bodies at will lacks with the current support for Bulk\nAPIs.</p>\n<p>The official client as well does not really take care of this issue - not\nblaming because the author's objective is to be as unopinionated as possible\nand this also gave us the chance to do it our way instead of adopt an existing\nimplementation. We wanted to use Bulk API the same way we would use individual\nAPIs. And why shouldn't it be the same! They are essentially individual\noperations put together and executed on a different end-point.</p>\n<p>Our solution for this was to provide a BulkClient which would allow you to\nstart a bulk operation, execute bulk operations in a way that you would execute\nindividual operations and then when you want to execute them together, it will\nmake the required request body and use the Elasticsearch client to make the\nrequest. Exposing bulk operations in a way that semantically look the same as\nindividual operations required us to implement APIs similar to individual APIs\non a very high level in the <code class=\"language-text\">BulkClient</code>.</p>\n<p>This is how the <code class=\"language-text\">BulkClient</code> works:</p>\n<p>{% highlight python %}\nfrom elasticsearch import Elasticsearch</p>\n<p>client = Elasticsearch(hosts=['localhost:9200'])</p>\n<p>bulk = BulkClient(client)\nbulk.index(index='test<em>index</em>1', doc<em>type='test</em>doc<em>type',\nbody=dict(key1='val1'))\nbulk.delete(index='test</em>index<em>2', doc</em>type='test<em>doc</em>type',\nid=123)\nbulk.update(index='test<em>index</em>3', doc<em>type='test</em>doc<em>type',\nid=456, body={\n'script': 'ctx.</em>source.count += count',\n'params': {\n'count': 1\n}\n})\nresp = bulk.execute()\n{% endhighlight %}</p>\n<h2 id=\"scroll-api\" style=\"position:relative;\"><a href=\"#scroll-api\" aria-label=\"scroll api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scroll API</h2>\n<p>The next problem we faced was with Scroll API.</p>\n<p>According to the documentation:</p>\n<blockquote>\n<p>While a search request returns a single \"page\" of results, the scroll API can\nbe used to retrieve large numbers of results (or even all results) from a\nsingle search request, in much the same way as you would use a cursor on a\ntraditional database.</p>\n</blockquote>\n<p>Scroll API is helpful if you want to work with a large number of documents -\nmore like get them out of Elasticsearch.</p>\n<p>The problem with Scroll API is that it requires you to do a lot of book\nkeeping. You have to keep <code class=\"language-text\">scroll_id</code> after every iteration to get the next set\nof documents. Depending upon your application, there is probably no work\naround. However, our use-case was to get a large number of documents all\ntogether. You can do that without Scroll API as well i.e. by using the size\nparameter where you can tell Elasticsearch how many documents to return and you\ncan ask it to return all documents by using the Count Search API first and then\npassing the size, but that will usually time out (or at least it did for us).\nSo what we did was scroll Elasticsearch in a loop and do the book keeping in\nthe code. And that was simple as well until we had to do it at multiple places</p>\n<ul>\n<li>there was no uniform way to do that and a lot of code repetition was done as\nwell.</li>\n</ul>\n<p>Our solution to this problem was to create a separate wrapper API only for this\npurpose and use that everywhere in our project. So we wrote a simple function\nthat would do the book-keeping for us and it could be used like so:</p>\n<p>{% highlight python %}\ndef scrolled_search(es, scroll, *args, **kwargs):\n'''\nIterator for Elasticsearch Scroll API.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">:param es: Elasticsearch client object\n:param str scroll: scroll expiry time according to Elasticsearch Scroll API\n                   docs\n\n... Note:: this function accepts `*args` and ``**kwargs`` and passes them\n           as they are to :meth:`Elasticsearch.search` method.\n&#39;&#39;&#39;\n\n...</code></pre></div>\n<p>es = Elasticsearch(hosts=['localhost:9200'])\nfor docs in scrolled_search(es, '10m', index='tweets'):\nfor doc in docs:\nprint doc\n{% endhighlight %}</p>\n<h3 id=\"iterator-based-scrolling-in-elasticsearch-py\" style=\"position:relative;\"><a href=\"#iterator-based-scrolling-in-elasticsearch-py\" aria-label=\"iterator based scrolling in elasticsearch py permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Iterator based Scrolling in elasticsearch-py</h3>\n<p>We must highlight that the official client also added support for iterator based\nscrolling later in the official client as a <strong><em>helper</em></strong>. We had already started\nusing our solution in our project and we find ours is slightly different than\ntheirs. For more details, <a href=\"https://elasticsearch-py.readthedocs.org/en/master/helpers.html#elasticsearch.helpers.scan\">read the docs here</a>.</p>\n<h2 id=\"superelasticsearch---elasticsearch-py-with-goodies\" style=\"position:relative;\"><a href=\"#superelasticsearch---elasticsearch-py-with-goodies\" aria-label=\"superelasticsearch   elasticsearch py with goodies permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SuperElasticsearch - elasticsearch-py with goodies!</h2>\n<p>Our solution to both the problems described earlier were based on the official\nElasticsearch client. After having solved these two problems, we figured that\ninstead of passing around the client object to our new API, it will be nicer if\nwe can use the new APIs in a way that it feels a part of the client itself. So\nwe went ahead and sub-classed the existing client class Elasticsearch to make\nit easier to use the new APIs. You can use the sub-classed client\nSuperElasticsearch like so:</p>\n<p>{% highlight python %}\nfrom superelasticsearch import SuperElasticsearch</p>\n<p>client = SuperElasticsearch(hosts=['localhost:9200'])</p>\n<h1 id=\"example-of-using-scrolled-search\" style=\"position:relative;\"><a href=\"#example-of-using-scrolled-search\" aria-label=\"example of using scrolled search permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example of using Scrolled Search</h1>\n<p>for doc in client.itersearch(index='test<em>index', doc</em>type'tweets',\nscroll='10m'):\n# do something with doc here\nprint doc</p>\n<h1 id=\"example-of-using-bulk-operations\" style=\"position:relative;\"><a href=\"#example-of-using-bulk-operations\" aria-label=\"example of using bulk operations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example of using Bulk Operations</h1>\n<p>bulk = client.bulk<em>operation()\nbulk.index(index='test</em>index<em>1', doc</em>type='test<em>doc</em>type',\nbody=dict(key1='val1'))\nbulk.delete(index='test<em>index</em>2', doc<em>type='test</em>doc<em>type',\nid=123)\nbulk.update(index='test</em>index<em>3', doc</em>type='test<em>doc</em>type',\nid=456, body={\n'script': 'ctx._source.count += count',\n'params': {\n'count': 1\n}\n})\nresp = bulk.execute()\n{% endhighlight %}</p>\n<p>This has also made it easy for us to do releases of SuperElasticsearch.\nSuperElasticsearch does not depend on the official client in ways that it will\nbreak compatibility with new releases of the official client, or if it will\nthen we can make the adjustments and come up with a new release. Basically it\nhas been written in a way to work with new versions of the official client with\nminimum friction. If a new release of the official client comes out, then you\nshould be able to upgrade to the new Elasticsearch client without upgrading\nSuperElasticsearch. This way we can try to keep developing SuperElasticsearch\nat its own pace and release only when we have new features to release or when\nit breaks compatibility. It also makes it easier for you to use the new APIs\nbecause you get all of them with the client object itself.</p>\n<p>SuperElasticsearch is available on <a href=\"https://github.com/wingify/superelasticsearch\">Github</a>.</p>","timeToRead":8,"excerpt":"We have been using Elasticsearch for storing analytics data.\nThis data stored in Elasticsearch is used in the Post Report Segmentationâ€¦","frontmatter":{"title":"SuperElasticsearch - More Python goodness in elasticsearch-py","author":"Vaidik Kapoor","authorslug":"vaidik_kapoor"},"fields":{"slug":"/posts/superlelasticsearch/","date":"October 06, 2015"}}},"pageContext":{"slug":"/posts/superlelasticsearch/","date":"2015-10-06T18:30:00.000Z","nexttitle":"Wingify at Meta Refresh 2015","nextslug":"/posts/meta-refresh-conference/","prevtitle":"Free objects - a generalized interpreter pattern","prevslug":"/posts/Free-objects/"}}}