{"componentChunkName":"component---src-templates-post-js","path":"/posts/elasticsearch-for-analytics/","result":{"data":{"markdownRemark":{"html":"<p><a href=\"https://www.elastic.co/products/elasticsearch\">Elasticsearch</a> is essentially a distributed search-engine but there have\nbeen more than one example of companies and projects using Elasticsearch for\nanalytics instead of search. We, at <a href=\"https://wingify.com\">Wingify</a>, had similar requirements when we\ndecided to make our analytics more powerful to empower the customers of our\nproduct, <a href=\"https://vwo.com\">Visual Website Optimizer (VWO)</a>. This blog post is about how we\nused Elasticsearch to make <a href=\"https://vwo.com\">VWO's</a> user tracking a lot more powerful than it\nearlier was.</p>\n<h2 id=\"the-problem\" style=\"position:relative;\"><a href=\"#the-problem\" aria-label=\"the problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Problem</h2>\n<p>For context, <a href=\"https://vwo.com\">VWO</a> is a tool that makes A/B testing of websites and mobile apps\nso simple so that there is no engineering intervention involved to run new\nA/B testing campaigns. Marketers and UI/UX designers do A/B testing to\nimprove online conversions and sales. <a href=\"https://vwo.com\">VWO</a> helps them with performing these A/B\ntests with almost no engineering knowledge.</p>\n<p>Since <a href=\"https://vwo.com\">VWO</a> is at the center of optimizing websites and mobile apps, this makes\nuser tracking important for our product - our users make use of the data we\ncollect to understand how their users (different segments of users) behave and\nmake optimization decisions accordingly. For example, in an A/B test campaign\nwith three variations, variation 2 might be winning for all the goals but for all\nthe users coming from India, variation 3 might be winning for all or some of the\ngoals. It should be possible for our customers to generate custom segmented\nreports and observe these different behaviours. </p>\n<p>So lets summarize how a campaign and its reporting should work:</p>\n<ul>\n<li>A <a href=\"https://vwo.com\">VWO</a> customer may create multiple campaigns. These campaigns have more\nthan one variations (variations are variants of web pages or iOS apps with UI\nchanges) that our customer wants to A/B test against real-traffic.</li>\n<li>Every campaign has more than one goals (goals are events that you want to track,\nsuch as visiting a particular page, clicking a DOM element, submitting a\nform, triggering a custom event with JavaScript etc.) which our customer wants\nus to track.</li>\n<li>Our JavaScript library tracks how real visitors trigger goals (events) per\nvariation and sends this data to our data collection end-points.</li>\n<li>Our data backend stores every visit and conversion for all the defined goals per\nvariation. This is stored on a day-wise basis.</li>\n<li>When the campaign's report is accessed, the day-wise visitor and goal conversion data\nis used in the statistics that go behind generating the report.</li>\n<li>Reports are generated considering behaviour of all the users who became a part\nof the campaign. However, our customers should have the flexibility to segment\nreports on the basis of parameters like location, browser, operating system,\ntime range, query parameters, traffic type, etc.</li>\n</ul>\n<h2 id=\"in-the-prehistoric-times\" style=\"position:relative;\"><a href=\"#in-the-prehistoric-times\" aria-label=\"in the prehistoric times permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>In the prehistoric times</h2>\n<p>We used to store only counters in our database (we use MySQL) i.e. for goal per\nvariation, we used to store number of visitors and conversions. Here is some\nsample data:</p>\n<pre>\n+------------+---------------+-----------+---------+-----------------+------+-------------+\n| account_id | experiment_id | variation | goal_id | event_date      | hits | conversions |\n+------------+---------------+-----------+---------+-----------------+------+-------------+\n|          1 |           198 | 2         |       1 | 2011-02-19      |   15 |          12 |\n|          1 |           198 | 1         |       1 | 2011-02-19      |   10 |           2 |\n|          1 |           198 | 2         |       1 | 2011-02-20      |    6 |           2 |\n|          1 |           198 | 1         |       1 | 2011-02-20      |   13 |           8 |\n|          1 |           198 | 1         |       2 | 2011-02-21      |    7 |           0 |\n|          1 |           198 | 1         |       1 | 2011-02-21      |    7 |           7 |\n|          1 |           198 | 2         |       2 | 2011-02-21      |    8 |           0 |\n|          1 |           198 | 2         |       1 | 2011-02-21      |    8 |           8 |\n|          1 |           198 | 2         |       2 | 2011-02-22      |    6 |           0 |\n|          1 |           198 | 1         |       1 | 2011-02-22      |    8 |           8 |\n+------------+---------------+-----------+---------+-----------------+------+-------------+\n</pre>\n<p>We also support revenue tracking for a goal. There is a different table for\nrevenue tracking, which looks something like this:</p>\n<pre>\n+------------+---------------+-----------+---------+-----------------+---------+\n| account_id | experiment_id | variation | goal_id | event_date      | revenue |\n+------------+---------------+-----------+---------+-----------------+---------+\n|          1 |           198 | 2         |       1 | 2011-02-19      |   32.43 |\n|          1 |           198 | 1         |       1 | 2011-02-19      |   34.35 |\n|          1 |           198 | 1         |       1 | 2011-02-19      |    6.13 |\n|          1 |           198 | 2         |       1 | 2011-02-19      |   21.93 |\n|          1 |           198 | 2         |       1 | 2011-02-20      |   83.36 |\n|          1 |           198 | 2         |       1 | 2011-02-20      |   72.65 |\n|          1 |           198 | 1         |       1 | 2011-02-20      |   56.14 |\n|          1 |           198 | 1         |       1 | 2011-02-20      |   87.12 |\n|          1 |           198 | 1         |       1 | 2011-02-21      |   78.25 |\n|          1 |           198 | 1         |       1 | 2011-02-21      |   88.36 |\n+------------+---------------+-----------+---------+-----------------+---------+\n</pre>\n<p>So when our customers want to view the report, our application's backend\nwill run some queries to generate aggregated metrics like total visitors per\ngoal per variation, total conversions per goal per variation, etc. which could\nbe taken care of using MySQL's built-in functions and then do some\nstatistics at the application level to decide winning variations per goal.</p>\n<p>Notice that in our first table where we store hits (visitors) and conversions,\nwe store total counters of these two metrics per goal per variation per day. In\nthe revenue table, we store every individual revenue per goal per variation\nwith the exact date they occurred on. We need these separately as we need to\ncalculate sum of squares of every revenue generated which is used in the\nstatistics. I am not going to delve in the statistics side of things because\nthat is out of scope of this article.</p>\n<p>This worked pretty well for us for a while. It was all very simple and we had\nto deal with aggregated data most of the times other than the case of revenue\nwhere in we had to get every row of revenue for a particular campaign. At the\napplication level, it was essentially firing up a few MySQL queries that would\ngive us the aggregated and day-wise data and then use that data to statistically\nfind winning variations per goal.</p>\n<p>But this setup had a major drawback. Our customers were restricted to the view\nof reports we would expose them to. It was not possible to drill down and\nunderstand how different segments of users are behaving as the complete picture\nmay not say it all about some different segments. For example, in an A/B test\ncampaign with three variations, variation 2 might be winning for all the goals\nbut for all the users coming from India, variation 3 might be winning for all\nor some of the goals. Finding this out was only possible by running another\ncampaign targeted to users from India on the basis of a hunch to understand if\nthe results would differ. And many times the results would not differ and our\ncustomers will lose visitors from their visitor quota.</p>\n<p>Furthermore, our data storage had a few other problems like no fine grain\ncontrol over date and time range (it was all day-wise), we would store all\nthe counters according to our customers' timezone (set at the time of account\ncreation) which means that changing timezone later would be possible but the\ndata collected earlier would be shown according to the previously selected\ntimezone. These were some major drawbacks to our way of storing visitor and\nconversion data.</p>\n<h2 id=\"new-age-reporting\" style=\"position:relative;\"><a href=\"#new-age-reporting\" aria-label=\"new age reporting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>New Age Reporting</h2>\n<p>We knew that our existing MySQL based setup was not perfect but more\nimportantly we realized that it does not help our customers. We wanted to make\nthings simpler for our customers so that:</p>\n<ul>\n<li>they could easily find important segments of users that behave\ndifferently and run targeted campaigns for them if necessary.</li>\n<li>they have finer control over date and time so that they can see reports\nat different steps like months, days, hours, minutes, etc.</li>\n<li>store everything in UTC so that we can take care of timezone changes at\napplication level.</li>\n</ul>\n<p>Looking at our application requirements, we realized that we cannot work with\njust aggregated data any more. We needed to start storing individual visitor's\ndata and their corresponding conversions to achieve flexibility and giving the\npower of slicing and dicing of the data in our customers' hands.</p>\n<p>We are also a pretty small team, which means that we wanted lesser headaches\nabout ops and maintaining the entire system in production. We wanted things to\nbe simple and as self-managed as possible.</p>\n<p>Our specific requirements were:</p>\n<ul>\n<li>Allow storage of individual visitor data with a lot of properties for\nperforming segmentation.</li>\n<li>Allow filtering on all the stored fields for performing segmentation.</li>\n<li>Allow full text search on a few fields.</li>\n<li>Capable of storing events for lifetime of a customer account. This means that\nwe cannot delete visitor data as long as our customer is with us.</li>\n<li>Getting consumable data out should be fast, or lets say not terribly slow. We\nare okay with an average of 2-3 seconds to start with.</li>\n<li>\n<p>Easy ops:</p>\n<ul>\n<li>Fault tolerant system. Failing nodes should not bring the service down.</li>\n<li>Scalable to handle our growing traffic, storage and other requirements.</li>\n</ul>\n</li>\n</ul>\n<p>We knew that Hadoop is the de-facto system in the Big Data universe but the\nentire Hadoop system is so vast that getting started with it is not as easy.\nThere tons of different tools in the Hadoop ecosystem and just selecting the\nright tools for your use-case may take a significant amount of time for\nresearch, leaving the implementation time aside. Also, running a Hadoop cluster\nis no piece of cake. There are so many moving parts that you are not completely\naware of as soon as you start. And performing upgrades of systems that have more\nsystems running with it will always be problematic. Further, tuning all these\nsystems to give an acceptable performance also seemed like a daunting task for a\nteam as small as our's with no prior experience with such systems.</p>\n<p>On top of the above problems that we got to know about Hadoop from our friends\nworking with it and from different blogs/websites, the task of implementing\nthe infrastructure requirements for Hadoop, building an implementation,\nmanaging in production and then repeating the cycle for a team of 2 engineers\nseemed like a daunting task.</p>\n<p>We knew that life would be much easy if we keep things simple and we started\nlooking at other options.</p>\n<h2 id=\"elasticsearch-to-the-rescue\" style=\"position:relative;\"><a href=\"#elasticsearch-to-the-rescue\" aria-label=\"elasticsearch to the rescue permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Elasticsearch to the rescue</h2>\n<p>Having worked with Elasticsearch before for a smaller project and remembering\nthat I had watched <a href=\"https://vimeo.com/44716955\">Shay's talk</a> from Berlin Buzzwords where he mentioned\nthat Elasticsearch was also being used for analytics, we started looking at\nElasticsearch to solve our problems.</p>\n<p>Elasticsearch supports filtering which we could use to filter visitors and\ntheir conversions on the basis of a lot of properties that we wanted to\ncollect for every visitor. Filtering would be fast in Elasticsearch because you\ncan have indexes on every field if you want and since Elasticsearch\nuses Lucene under-the-hood, we were confident about its indexing\ncapabilities. Elasticsearch supports full text search out-of-the-box.\nThis fits well with our basic application requirements. On top of this,\nElasticsearch supported Faceting (when we were evaluating, aggregations\nframeworks was not there) which we could exploit for analytics. That means we\ndon't even have to get all the data out of Elasticsearch to our application\nlayer. Elasticsearch is capable of giving us an aggregated view of the data we\nwere storing.</p>\n<p>This was just amazing for us. We were able to build a PoC within two weeks. The\nnext couple of months were spent on understanding Elasticsearch better,\noptimizing our implementation, testing Elasticsearch against production load\nand tuning it for the same.</p>\n<p>In the meantime, Elasticsearch released 1.0.0 with aggregation framework and we\nquickly moved from using <a href=\"http://www.elastic.co/guide/en/elasticsearch/reference/current/search-facets.html\">Facets</a> (see <a href=\"https://en.wikipedia.org/wiki/Faceted_search\">Faceted Search</a>) to Aggregations.\n<a href=\"http://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html\">Aggregations</a> proved to be very useful with revenue goals as we could just\nask Elasticsearch to give us sum of squares of individual revenues without\ngetting individual revenues out of Elasticsearch.</p>\n<p>As pointed out earlier, we need to track individual users. How we do this is\nwe create a document for a unique visitor per account per campaign in\nElasticsearch. This document stores user meta data, data for segmentation and\ngoal conversion tracking data. A typical visitor document looks like this:</p>\n<p>{% highlight json %}\n{\n\"<em>index\": \"february-2015\",\n\"</em>type\": \"123\",\n\"<em>id\": \"D2E0A04858025DFE23928BC1F70D2156</em>123<em>313\",\n\"</em>score\": 1,\n\"<em>source\": {\n\"query</em>params\": [\n{\n\"val\": \"val1\",\n\"param\": \"param1\"\n},\n{\n\"val\": \"val2\",\n\"param\": \"param2\"\n}\n],\n\"browser<em>string\": \"Chrome 40.0.2214\",\n\"ip\": \"8.8.8.0\",\n\"screen</em>colors\": \"24\",\n\"browser<em>version\": \"40.0.2214\",\n\"session\": 1,\n\"device</em>type\": \"Desktop\",\n\"document<em>encoding\": \"UTF-8\",\n\"variation</em>goals<em>facet</em>term\": \"c1<em>g1\",\n\"ts\": 1424348107,\n\"hour</em>of<em>day\": 12,\n\"os</em>version\": \"\",\n\"experiment\": 313,\n\"user<em>time\": \"2015-02-19T12:15:07.271000\",\n\"direct</em>traffic\": false,\n\"variation\": \"1\",\n\"ua\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.111 Safari/537.36\",\n\"search<em>traffic\": false,\n\"social</em>referrer\": \"youtube\",\n\"returning<em>visitor\": false,\n\"hit</em>time\": \"2015-02-19T12:15:07\",\n\"user<em>language\": \"en-us\",\n\"device\": \"Other\",\n\"active</em>goals\": [\n1\n],\n\"account\": 196,\n\"url\": \"<a href=\"https://vwo.com/lp/ab-testing-tool/?gclid=CPiZ7JT-7cMCFfDKtAodPUwAhQ%22\">https://vwo.com/lp/ab-testing-tool/?gclid=CPiZ7JT-7cMCFfDKtAodPUwAhQ\"</a>,\n\"country\": \"United Kingdom\",\n\"day<em>of</em>week\": \"Thursday\",\n\"converted<em>goals\": [\n1\n],\n\"social</em>traffic\": true,\n\"converted<em>goals</em>info\": [\n{\n\"id\": 1,\n\"facet<em>term\": \"1</em>1\",\n\"conversion_time\": \"2015-02-19T12:15:54\"\n}\n],\n\"referrer\": \"<a href=\"https://www.youtube.com/watch?v=EM-5IxL4HwQ%22\">https://www.youtube.com/watch?v=EM-5IxL4HwQ\"</a>,\n\"browser\": \"Chrome\",\n\"os\": \"Windows 7\",\n\"email_traffic\": false\n}\n}\n{% endhighlight %}</p>\n<p><code class=\"language-text\">_id</code> is the UUID of the visitor. Most of the other fields have\ninformation extracted out from the IP address, the User Agent, the URL and the\nReferring URL.</p>\n<p>All the fields except a few are some fields with their types correctly set.\nIndexes are maintained on all of them so that visitor documents can be filtered\naccording to the values in these fields.</p>\n<p>But there are a few fields that are interesting:</p>\n<ul>\n<li>query_params</li>\n<li>converted<em>goals</em>info</li>\n<li>converted<em>goals</em>info.facet_term</li>\n<li>variation<em>goals</em>facet_term</li>\n</ul>\n<p>Let's look at each of them one-by-one.</p>\n<ul>\n<li><strong>query_params</strong> is an array of objects for storing query parameters and their\nrespective values. This is of type <code class=\"language-text\">nested</code> because our customers may want to\nfind all visitors and their conversions who visited pages with certain query\nparameters. Consider a scenario where you want to find all visitor documents\nwith query parameter <code class=\"language-text\">param1</code> and <code class=\"language-text\">val2</code>. A simple <code class=\"language-text\">bool must</code> query with\nterm query would return the above document if <code class=\"language-text\">query_params</code> was not nested\nbecause it would find one of the two <code class=\"language-text\">query_params.param</code> values to be equal\nto <code class=\"language-text\">param1</code> and the one of the two <code class=\"language-text\">query_params.val</code> values to be equal to\n<code class=\"language-text\">val2</code> but we know that <code class=\"language-text\">param1</code> never had <code class=\"language-text\">val2</code> as its value. This happens\nbecause each object in <code class=\"language-text\">query_params</code> array is not considered as an individual\ncomponent of the document. <code class=\"language-text\">nested</code> types solve this problem. Read more about\n<code class=\"language-text\">nested</code> documents and relations in Elasticsearch in this <a href=\"https://www.elastic.co/blog/managing-relations-inside-elasticsearch/\">blog post</a>.</li>\n<li><strong>converted<em>goals</em>info</strong> is also an array of objects for storing information\nof individual goal conversions. Here we store <code class=\"language-text\">goal_id</code> of the converted goal,\nthe time of conversion as a DateTime field and another field that we will\nshortly discuss. This field is also of <code class=\"language-text\">nested</code> type for the same reason as\nwith <code class=\"language-text\">query_params</code>.</li>\n<li><strong>converted<em>goals</em>info.facet_term</strong> and <strong>variation<em>goals</em>facet_term</strong> need to\nbe discussed together because their values are constructed in a similar way.\nThey in particular don't hold any new information. In the beginning of the\npost, we saw how we used to store aggregated visitor and conversion count per\ngoal per variation per day. We still need that data out of Elasticsearch in a\nsimilar way for our statistics. The day-wise problem gets solved by using\nday-wise buckets in aggregations framework. The next problem is getting visitor\ncounts per variation per goal. In MySQL terms, we would want to run a GROUP BY\nquery on <code class=\"language-text\">variation</code> and <code class=\"language-text\">goal_id</code> column. In Elasticsearch, we can do\nsomething similar by using <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-script\">Terms Aggregation using Scripts</a>. The problem\nwith this approach is that if you have a large number of documents, your\nscript will get evaluated on all of them and Elasticsearch is not really a\nscript execution engine (no matter which scripting plugin you use). What you\ncan do instead is push the result of a script at the time of indexing and then\nsimply run Terms Aggregation on it. We saw massive performance boost by doing\nthis performance hack.</li>\n</ul>\n<p>Every document gets saved under the <code class=\"language-text\">doc_type</code> for the account that campaign\nbelongs to i.e. every account on <a href=\"https://vwo.com\">VWO</a> has a separate doc type.</p>\n<h3 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance</h3>\n<p>From performance point-of-view, Elasticsearch has very fast indexing and\nquerying capabilities. It is a distributed system - you can deploy a cluster\nof nodes in production which stores indexes in a distributed fault-tolerant\nway to give you performance benefits. Increase the number of replicas per shard\nand you can scale reads and queries. This can be done after creating an index as\nwell. Elasticsearch does not allow changing of number of shards though. But\nthere is a sweet work around for that. Just create a new index with more shards\nand use aliases, and you can now scale indexing as well.</p>\n<h4 id=\"sharding\" style=\"position:relative;\"><a href=\"#sharding\" aria-label=\"sharding permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sharding</h4>\n<p>From our experience with working on large data sets which need to be queried on\nan ad-hoc basis and have low latency requirements and from our learning from\n<a href=\"http://thedudeabides.com/\">Shay's</a> talks (<a href=\"https://www.youtube.com/watch?v=SIj5eJw8BUE\">1</a>, <a href=\"https://www.youtube.com/watch?v=fEsmydn747c\">2</a>, <a href=\"https://vimeo.com/44716955\">3</a>), we understood that a data storage\nsystem meant to store a lot\nof data will scale for your reads and querying requirements well if you can\nshard your data well according to the variable that determines the growth of\nthat data. For example, if you are using any database for storing machine logs,\nyou should be able to shard your data probably according to time because you\nwould want to query the most recent data and if you have to do it from the all\nthe data you ever collected, then your old data will only become a performance\nbottleneck. So a possible sharding strategy could be sharding data according to\nmonth-year.</p>\n<p>Our requirement was similar. We get visitor data which we could easily shard\non monthly basis. And since this data would keep on growing, we can just add new\nindexes every month and place the new data in these indexes. However, which\nindex a visitor document goes to is not determined by the timestamp of the\nvisitor but it is determined by the date of creation of the campaign. Why? Our\ncustomers view campaign reports i.e. when a campaign report is opened, we want\nto get data for that campaign only. So it would make sense to have all the data\nfor a campaign reside only in one index because we wouldn't want to look into\nmultiple indexes for generating report of one campaign. If we decided to put\nvisitor documents in different indexes depending upon time of visit, we would\nhave faced the following problems:</p>\n<ul>\n<li>A campaign may run for more than a month, so visitor documents for a campaign\nmay be in more than one indexes and we would not have any way to know which\nall indexes without keeping a track of it separately as to which indexes have\nvisitors for a given campaign. This would be painful.</li>\n<li>Since visitors also convert goals and we store conversion data in visitor\ndocuments, it would be very difficult for us to find which index to find the\nvisitor document in so that we can add conversion tracking related data in the\ndocument.</li>\n</ul>\n<p>These problems get solved when we restrict all visitor data for a given campaign\nto go in one index only. So for <code class=\"language-text\">account_id</code> 123 that has two campaigns -\ncampaign 1 (created in January 2015) and campaign 2 (created in February 2015),\nthe visitor documents for both will be created in the indexes for January 2015\nand February 2015 respectively.</p>\n<p>Another big advantage of this is that we can adjust the number of shards every\nmonth. So if we are seeing a trend of more visitors getting tracked month after\nmonth, in the next month we can create a new index with more shards than the\nprevious month's index.</p>\n<h4 id=\"routing\" style=\"position:relative;\"><a href=\"#routing\" aria-label=\"routing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Routing</h4>\n<p>Since documents are stored in a particular shard in an index, Elasticsearch\nneeds to decide which shard to put the document in. Elasticsearch use a hashing\nalgorithm that is used for shard selection and Elasticsearch uses document's ID\nby default for determining which shard that document goes into. This is called\nrouting a document into a shard. This may work fine in some cases. But the\ndrawback of this default routing strategy is felt when you have a large number\nof shards and also when you have to serve a lot of queries. The drawback is that\nElasticsearch now needs to search every shard in an index for all the documents\nmatching a given query, wait for the results, aggregate them and then return the\nfinal result. So for a given query, all shards get busy.</p>\n<p>This can be controlled by using a better routing strategy. In our case, we\ngenerate reports of a campaign of a given account. It would be ideal that one\naccount does not limit report generation of another account. So instead of going\nwith the default routing strategy, we decided to route documents on the basis of\n<code class=\"language-text\">account_id</code>. So now, when a campaign report is generated for a given account,\nthe query hits only a single shard, leaving all other shards available for\nserving other queries and also freeing up CPU resources. After moving to this\nrouting strategy, we saw a significant reduction in CPU usage in our cluster.</p>\n<h3 id=\"operations\" style=\"position:relative;\"><a href=\"#operations\" aria-label=\"operations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Operations</h3>\n<p>From operations and management point-of-view, Elasticsearch is fault tolerant -\nindexes can be sharded and replicated and distributed in a cluster.\nElasticsearch distributes shards and their replicas on different nodes in the\ncluster so that if a node fails, Elasticsearch promotes replicas to be the\nprimary shards and moves shards and replicas in the cluster to balance the\ncluster. What is really amazing is that Elasticsearch also gives control over\nplacement of shards in a cluster so that it is easy for you to separate hot\ndata from cold (historic) data easily. We have not had the need to use this\nfeature yet, but it is good to know that we can do this if at all historic data\nbecomes a performance problem. Chances are that it will become a problem but\nprobably much later.</p>\n<h2 id=\"drawbacks\" style=\"position:relative;\"><a href=\"#drawbacks\" aria-label=\"drawbacks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Drawbacks</h2>\n<p>Although Elasticsearch made it really easy for us to push out something like\nthis with so much ease (and remember we had no experience building something\nlike this before) and we love Elasticsearch for that, we did find a few things\nwith it that we think limits us.</p>\n<ul>\n<li>The facet term hack for avoiding running scripts works great but then it's also\nlimiting if you want to add new features in your application that rely on\ndifferent scripts that were not added at the time of indexing. This means that\nyou will have to re-index all your data if you want to support this new\nfeature or just provide this feature on new data.</li>\n<li>Lack of JOINS becomes limiting. As of now we push the conversion data in\nvisitor document. But it would have been ideal if we could independently index\nconversions data in a separate index or doc type.</li>\n</ul>\n<p>We don't know how to solve these problems yet or if Elasticsearch team has any\nplans for bringing something new that fixes these problems. It will open\nElasticsearch to a lot more possibilities if JOINS were possible. But we also\nunderstand that it's not a simple problem to solve and Lucene and Elasticsearch\nwere not made keeping these use-cases in mind. Nevertheless, we hope to see\nthese improving in the future, especially because a lot of companies are using\nElasticsearch for analytics as well.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>Elasticsearch has been great for us and it proves that you don't always need\nHadoop for building analytics depending upon your requirements. The amazing\nthing is that we feel Elasticsearch is amazing when it comes to scaling when\nlimited by resources - horizontal scaling is extremely simple. But it will work\nfor you or not depends entirely on your requirements.</p>\n<p>Elasticsearch already works with Hadoop, which is being further developed to\nexpand the use-cases it can support. This gives us a lot of confidence as we\nwill add more features to <a href=\"https://vwo.com\">VWO's</a> user tracking in the future and we know that we\nwill not be limited by our decision to use Elasticsearch.</p>","timeToRead":18,"excerpt":"Elasticsearch is essentially a distributed search-engine but there have\nbeen more than one example of companies and projects usingâ€¦","frontmatter":{"title":"Elasticsearch for Analytics","author":"Vaidik Kapoor","authorslug":"vaidik_kapoor"},"fields":{"slug":"/posts/elasticsearch-for-analytics/","date":"March 26, 2015"}}},"pageContext":{"slug":"/posts/elasticsearch-for-analytics/","date":"2015-03-26T18:30:00.000Z","nexttitle":"Meta Refresh 2015 Delhi Run-Up Event","nextslug":"/posts/meta-refresh-run-up/","prevtitle":"Q-Directives - A Faster Directive System For Angular.js","prevslug":"/posts/q-directives/"}}}